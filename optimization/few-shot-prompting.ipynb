{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56f6b50-d708-43c5-acd2-ad948cdc1797",
   "metadata": {},
   "source": [
    "## Optimization with LangSmith\n",
    "\n",
    "Prompt engineering isn't always the most fun. You can use data to optimize the prompt for you with the help of tools like LangSmith. Main steps are:\n",
    "1. Create a dataset\n",
    "2. Pick a metric to improve\n",
    "3. Create an initial chain\n",
    "4. Decide the update logic (few-shot examples vs. instruction teaching vs. other methods, how to format the examples, etc.)\n",
    "5. Train!\n",
    "\n",
    "\n",
    "Below is an example bootstrapping a gpt-3.5-turbo model on an entailment task using few-shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191baa94-41b2-4aaf-b621-aaf8171566d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langsmith langchain_openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f9596-dcd5-4928-a6f0-e4f75e1cf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR API KEY\"  # Update with your API key\n",
    "# We are using openai here as well\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ac85d1-d72f-482e-8488-6a848ae98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461b3958-1b1a-47aa-a2f8-02c6119eb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add clone steps\n",
    "public_datasets = [\n",
    "    \"https://smith.langchain.com/public/1d065de2-56c1-496e-bc66-bdce308e6537/d\",  # train\n",
    "    \"https://smith.langchain.com/public/fdf16166-1edd-418f-b777-3af82034931d/d\",  # dev\n",
    "    \"https://smith.langchain.com/public/8d40d210-f8e6-4def-a206-78c5080c5d53/d\",  # test\n",
    "]\n",
    "for ds in public_datasets:\n",
    "    client.clone_public_dataset(ds)\n",
    "train_name = \"scone-train\"\n",
    "dev_name = \"scone-dev\"\n",
    "test_name = \"scone-test-one-scoped\"\n",
    "full_test_name = \"scone-test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810e70c-9518-4bf4-a50f-bd52296b145d",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedc05f4-bc20-4de5-912d-51123e4b38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': 'A man who does not walk confidently dropping produce.', 'question': 'Can we logically conclude for sure that a man who does not walk confidently dropping kale?'}\n",
      "{'answer': 'No', 'category': 'one_not_scoped'}\n"
     ]
    }
   ],
   "source": [
    "example = next(client.list_examples(dataset_name=train_name))\n",
    "print(example.inputs)\n",
    "print(example.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33084e53-ba37-4274-892c-f4d02ce3c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import run_evaluator\n",
    "\n",
    "\n",
    "@run_evaluator\n",
    "def exact_match(run, example):\n",
    "    predicted = run.outputs[\"output\"]\n",
    "    expected = example.outputs[\"answer\"]\n",
    "    expected_bool = {\"no\": False, \"yes\": True}.get(expected.strip().lower())\n",
    "    score = expected_bool == predicted.is_entailed\n",
    "    return {\n",
    "        \"key\": \"exact_match\",\n",
    "        \"score\": int(score),\n",
    "        \"comment\": f\"predicted={predicted}\\nexpected={expected}={expected_bool}\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012b34ab-e6eb-4d76-a55f-24bbdcd97d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wfh/.pyenv/versions/3.11.2/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class EntailmentOutput(BaseModel):\n",
    "    reasoning: str = Field(\n",
    "        description=\"Think step-by-step to avoid any logical errors in your decision\"\n",
    "    )\n",
    "    is_entailed: bool\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a logical expert in predicting entailment.{examples}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Can you logically conclude the hypothesis given the premise?\\n\"\n",
    "            \"Hypothesis: {question}\\n\"\n",
    "            \"Premise: {context}\\n\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(examples=\"\")\n",
    "chain = prompt | ChatOpenAI(model=\"gpt-3.5-turbo\").with_structured_output(\n",
    "    schema=EntailmentOutput\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073c51af-1a53-4530-885d-099f56bf27fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntailmentOutput(reasoning='If a man drops produce and kale is a type of produce, then it can be logically concluded that a man who does not walk confidently drops kale.', is_entailed=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = chain.invoke(example.inputs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce97acf-4150-4ef1-a8f3-6710c99779a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'No', 'category': 'one_not_scoped'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dda2b0-e4f7-4394-9b65-6f4316399392",
   "metadata": {},
   "source": [
    "## Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b596b83-29b5-4a2d-9e42-8b2a3e75114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'advanced-page-6' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9/compare?selectedSessions=6d52ffb4-f7f5-4a65-896e-c35566b67acf\n",
      "\n",
      "View all tests for Dataset scone-dev at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9\n",
      "[------------------------------------------------->] 50/50"
     ]
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    custom_evaluators=[exact_match],\n",
    ")\n",
    "\n",
    "res = client.run_on_dataset(\n",
    "    dataset_name=dev_name,\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=eval_config,\n",
    "    project_metadata={\"optimizer\": None},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9236d-a213-4cf6-815e-fd05a248105a",
   "metadata": {},
   "source": [
    "Got about ~55% on it. Whoopy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192913d-e9c1-4f00-aa41-badc64c6b21d",
   "metadata": {},
   "source": [
    "## ✨ Optimize ✨\n",
    "\n",
    "\n",
    "This just means \"use data to update system and improve metric\". LangChain runnables don't natively support a \"backwards\" method (a la pytorch), but you can pretty easily define updates/mutations for most of them.\n",
    "\n",
    "For instance:\n",
    "- Few shot prompting: add an additional string input or MessagesPlaceholder in the prompt template\n",
    "- Updating the Instructions: just update the prompt template directly (likely the system prompt)\n",
    "- etc.\n",
    "\n",
    "If you had a completely unconstrained search space, it'll be an expensive and hard-to tune system. (e.g., NAS hasn't been that successfull in the industry).\n",
    "\n",
    "\n",
    "Projects like DSPy have a bunch of off-the-shelf optimizers that encapsulate logic for mutating the model based on metrics. For instance the `BootstrapFewShotWithRandomSearch` does the following in order:\n",
    "\n",
    "1. Zero shot eval - This is really a No-Op in their code.\n",
    "2. Labeled few shot randomly sample K from the training set\n",
    "3. Bootstrapped few shot - go through training examples, predict with the base model, if it gets it right, add it to the few-shot pool\n",
    "(repeat (3) for N candidate programs)\n",
    "\n",
    "\n",
    "You can configure additional branching in (3) and (2). It's pretty similar to a genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89796b5a-a1f3-41ae-b773-3897798b40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define how we want our few-shot examples to be formatted\n",
    "import random\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def format_example(example: dict):\n",
    "    inputs = example[\"input\"]\n",
    "    outputs = example[\"output\"]\n",
    "    return f\"Hypothesis: {inputs['question']}\\nPremise: {inputs['context']}\\nAnswer: {outputs}\"\n",
    "\n",
    "\n",
    "def format_few_shot(input_: dict, examples: Optional[List[dict]] = None):\n",
    "    if examples:\n",
    "        # TODO: make this configurable / bound to the prompt template\n",
    "        input_[\"examples\"] = \"\\n\\n## Examples\\n\" + \"\\n\".join(\n",
    "            f\"{i}: {format_example(e)}\" for i, e in enumerate(examples)\n",
    "        )\n",
    "    return input_\n",
    "\n",
    "\n",
    "# And we will create a placeholder in the template to add few-shot examples\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a logical expert in predicting entailment.{examples}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Can you logically conclude the hypothesis given the premise?\\n\"\n",
    "            \"Hypothesis: {question}\\n\"\n",
    "            \"Premise: {context}\\n\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(examples=\"\")\n",
    "\n",
    "\n",
    "def create_chain(examples: Optional[List] = None):\n",
    "    chain = (\n",
    "        RunnableLambda(format_few_shot).bind(examples=examples)\n",
    "        | prompt\n",
    "        | ChatOpenAI(model=\"gpt-3.5-turbo\").with_structured_output(\n",
    "            schema=EntailmentOutput\n",
    "        )\n",
    "    ).with_config(tags=[\"to_train\"])\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "709d4bdf-e452-45d7-a97d-e2e8e1dd595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(\n",
    "    chain,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    eval_config,\n",
    "    examples=None,\n",
    "    k: int = 5,\n",
    "):\n",
    "    collected = examples.copy() if examples else {}\n",
    "    train_results = client.run_on_dataset(\n",
    "        dataset_name=train_dataset,\n",
    "        llm_or_chain_factory=chain,\n",
    "        evaluation=eval_config,\n",
    "    )\n",
    "    # Or could query langsmith, but there's a lag there.\n",
    "    df = train_results.to_dataframe()\n",
    "    feedback_keys = [c for c in df.columns if c.startswith(\"feedback.\")]\n",
    "    passing = df[\n",
    "        df.apply(lambda x: bool(x[feedback_keys].values.all()), axis=1)\n",
    "    ].index.tolist()\n",
    "    for passing_idx in passing:\n",
    "        if passing_idx not in collected:\n",
    "            collected[passing_idx] = train_results[\"results\"][passing_idx]\n",
    "\n",
    "    return collected\n",
    "\n",
    "\n",
    "def eval(eval_dataset, chain, eval_config, step_n) -> float:\n",
    "    dev_results = client.run_on_dataset(\n",
    "        dataset_name=eval_dataset,\n",
    "        llm_or_chain_factory=chain,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_metadata={\n",
    "            \"step\": step_n,\n",
    "        },\n",
    "    )\n",
    "    df = dev_results.to_dataframe()\n",
    "    feedback_key = [c for c in df.columns if c.startswith(\"feedback.\")][0]\n",
    "    # Assume single metric rn ha\n",
    "    return df[feedback_key].mean()\n",
    "\n",
    "\n",
    "def train(\n",
    "    chain_constructor,\n",
    "    train_dataset,\n",
    "    eval_dataset,\n",
    "    eval_config,\n",
    "    steps: int = 4,\n",
    "    k: int = 5,\n",
    "):\n",
    "    best_score = eval(eval_dataset, chain_constructor(), eval_config, 0)\n",
    "    best_step = 0\n",
    "    examples = None\n",
    "    for step_number in range(steps):\n",
    "        chain = chain_constructor(examples)\n",
    "        collected = step(chain, train_dataset, eval_dataset, eval_config, k=k)\n",
    "        foo = collected\n",
    "        # TODO: probably want some diversity of labels here lol\n",
    "        selected = random.sample(sorted(collected), k)\n",
    "        sampled_examples = {k: collected[k] for k in selected}\n",
    "        selected_examples = list(selected_examples.values())\n",
    "        updated_chain = chain_constructor(examples=selected_examples)\n",
    "        updated_score = eval(eval_dataset, updated_chain, eval_config, step_number + 1)\n",
    "        if updated_score > best_score:\n",
    "            print(\n",
    "                f\"New best score {updated_score} > {best_score}. Updating selected examples.\"\n",
    "            )\n",
    "            examples = selected_examples\n",
    "            best_step = step_number + 1\n",
    "        else:\n",
    "            print(\"Underperformed. Continuing\")\n",
    "    print(\"Best overall score: \", best_score)\n",
    "    print(\"Best step: \", best_step)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb42676-8fb1-4eca-bf50-29f9d2225ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'kind-wall-40' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9/compare?selectedSessions=249f8b54-4488-4435-b288-a73da66e6ae3\n",
      "\n",
      "View all tests for Dataset scone-dev at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9\n",
      "[------------------------------------------------->] 50/50"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.exact_match</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f91c0f8c-d27a-49e4-92c6-0ea20ecd6d07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.674155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.503457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.493475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.376178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.572887</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.894788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.193269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.exact_match error  execution_time  \\\n",
       "count              50.000000     0       50.000000   \n",
       "unique                   NaN     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                0.540000   NaN        1.674155   \n",
       "std                 0.503457   NaN        0.493475   \n",
       "min                 0.000000   NaN        1.073126   \n",
       "25%                 0.000000   NaN        1.376178   \n",
       "50%                 1.000000   NaN        1.572887   \n",
       "75%                 1.000000   NaN        1.894788   \n",
       "max                 1.000000   NaN        4.193269   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     50  \n",
       "unique                                    50  \n",
       "top     f91c0f8c-d27a-49e4-92c6-0ea20ecd6d07  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'helpful-potato-26' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073/compare?selectedSessions=ca3f35e2-2450-4dde-8da3-c77e5c0abc28\n",
      "\n",
      "View all tests for Dataset scone-train at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073\n",
      "[------------------------------------------------->] 200/200View the evaluation results for project 'helpful-cushion-72' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9/compare?selectedSessions=9fc32a64-7fd9-4bcc-9f8c-03269342270f\n",
      "\n",
      "View all tests for Dataset scone-dev at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9\n",
      "[------------------------------------------------->] 50/50"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.exact_match</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f0c09a8f-5ace-4514-82ba-7b8714a29216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.758317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.480888</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.119977</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.471870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.660316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.890199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.636871</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.exact_match error  execution_time  \\\n",
       "count              50.000000     0       50.000000   \n",
       "unique                   NaN     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                0.580000   NaN        1.758317   \n",
       "std                 0.498569   NaN        0.480888   \n",
       "min                 0.000000   NaN        1.119977   \n",
       "25%                 0.000000   NaN        1.471870   \n",
       "50%                 1.000000   NaN        1.660316   \n",
       "75%                 1.000000   NaN        1.890199   \n",
       "max                 1.000000   NaN        3.636871   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     50  \n",
       "unique                                    50  \n",
       "top     f0c09a8f-5ace-4514-82ba-7b8714a29216  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score. Updating selected examples.\n",
      "View the evaluation results for project 'memorable-place-30' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073/compare?selectedSessions=bd87407c-c890-4574-a21b-819ee5cb2df6\n",
      "\n",
      "View all tests for Dataset scone-train at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073\n",
      "[------------------------------------------------->] 200/200View the evaluation results for project 'bold-scarecrow-92' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9/compare?selectedSessions=799181f4-892f-4910-980d-3fafe05ec092\n",
      "\n",
      "View all tests for Dataset scone-dev at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/1bba4039-6f9c-4309-b09b-04453af5edc9\n",
      "[------------------------------------------------->] 50/50"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.exact_match</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2a42e116-6ada-4762-8215-4ae920a23773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.858655</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.501427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503588</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.165229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.510991</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.818283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.103101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.858595</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.exact_match error  execution_time  \\\n",
       "count              50.000000     0       50.000000   \n",
       "unique                   NaN     0             NaN   \n",
       "top                      NaN   NaN             NaN   \n",
       "freq                     NaN   NaN             NaN   \n",
       "mean                0.560000   NaN        1.858655   \n",
       "std                 0.501427   NaN        0.503588   \n",
       "min                 0.000000   NaN        1.165229   \n",
       "25%                 0.000000   NaN        1.510991   \n",
       "50%                 1.000000   NaN        1.818283   \n",
       "75%                 1.000000   NaN        2.103101   \n",
       "max                 1.000000   NaN        3.858595   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     50  \n",
       "unique                                    50  \n",
       "top     2a42e116-6ada-4762-8215-4ae920a23773  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score. Updating selected examples.\n",
      "View the evaluation results for project 'warm-sofa-98' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073/compare?selectedSessions=8a4c0794-1b74-4265-8bd4-3d3fbc07e0ad\n",
      "\n",
      "View all tests for Dataset scone-train at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/c4a2ec92-6e2c-4004-af24-7654f507a073\n",
      "[------------------------------------------------->] 199/200"
     ]
    }
   ],
   "source": [
    "examples = train(create_chain, train_name, dev_name, eval_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d3e2d-e719-4328-babf-0b230b37d49a",
   "metadata": {},
   "source": [
    "## Compare on held-out set\n",
    "\n",
    "It's easy to overfit a benchmark if you do model selection on it. Let's compare models on the test set we had held-out before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2d5a9-00c6-47df-bc82-53a18008e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = create_chain()\n",
    "best_performing_model = create_chain(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793f7a-0406-4a41-b12b-10d63450df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in [\n",
    "    (\"original\", original_model),\n",
    "    (\"optimized\", best_performing_model),\n",
    "]:\n",
    "    client.run_on_dataset(\n",
    "        dataset_name=test_dataset,\n",
    "        llm_or_chain_factory=model,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_metadata={\n",
    "            \"model\": model_name,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbba45d-ee84-4ad1-891b-4e3864d3b361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
