{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56f6b50-d708-43c5-acd2-ad948cdc1797",
   "metadata": {},
   "source": [
    "## Prompt-tuning with LangSmith + Claude\n",
    "\n",
    "Prompt engineering isn't always the most fun, especially when it comes to tasks where metrics are hard to defined.\n",
    "\n",
    "Turns out LLMs can do a [decent job at prompt engineering](https://arxiv.org/abs/2211.01910), especially when incorporating human feedback on representative data.\n",
    "\n",
    "LangSmith makes this this whole flow very easy. Let's give it a whirl!\n",
    "\n",
    "This example is based on [@alexalbert__'s example Claude workflow](https://x.com/alexalbert__/status/1767258557039378511?s=20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191baa94-41b2-4aaf-b621-aaf8171566d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langsmith langchain_anthropic langchain sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20f9596-dcd5-4928-a6f0-e4f75e1cf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR API KEY\"  # Update with your API key\n",
    "# We are using Anthropic here as well\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4cf23c-c99f-4206-99cc-2b2020fa5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set an LLM cache in case you want to re-run the steps\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ac85d1-d72f-482e-8488-6a848ae98c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb8d0a-7618-4d93-ae82-ae150a3acc28",
   "metadata": {},
   "source": [
    "# 1. Pick a task\n",
    "\n",
    "Let's say I want to write a tweet generator about academic papers, one that is catchy but not laden with too many buzzwords\n",
    "or impersonal. Let's see if we can \"optimize\" a prompt without having to engineer it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d087d0-4a76-4046-82d7-dddf8361bad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your task is to write an engaging tweet to market the following academic paper or open source project:\n",
      "\n",
      "<paper>\n",
      "{paper}\n",
      "</paper>\n",
      "\n",
      "Pay close attention to the abstract or project summary, as that will contain the key points you'll want to highlight in the tweet.  Think carefully about how to concisely summarize the work in a way that will be interesting and appealing to a broad audience on Twitter. \n",
      "\n",
      "The tweet should strike a balance between being clear and informative about the work, while also using some marketing language to generate excitement and interest. However, avoid being gimmicky or relying too heavily on buzzy jargon.  Focus on substance over style.\n",
      "\n",
      "Write out the full text of your proposed tweet inside <tweet> tags. The tweet must be under 280 characters in length.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "task = (\n",
    "    \"Generate a tweet to market an academic paper or open source project. It should be\"\n",
    "    \" well crafted but avoid gimicks or over-reliance on buzzwords.\"\n",
    ")\n",
    "\n",
    "\n",
    "# See: https://smith.langchain.com/hub/wfh/metaprompt\n",
    "prompt = hub.pull(\"wfh/metaprompt\")\n",
    "llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "\n",
    "\n",
    "def get_instructions(gen: str):\n",
    "    return gen.split(\"<Instructions>\")[1].split(\"</Instructions>\")[0]\n",
    "\n",
    "\n",
    "meta_prompter = prompt | llm | StrOutputParser() | get_instructions\n",
    "\n",
    "\n",
    "recommended_prompt = meta_prompter.invoke(\n",
    "    {\n",
    "        \"task\": task,\n",
    "        \"input_variables\": \"\"\"\n",
    "{paper}\n",
    "\"\"\",\n",
    "    }\n",
    ")\n",
    "print(recommended_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac4c64-98f8-43e4-ad63-a7797a9b6396",
   "metadata": {},
   "source": [
    "OK so it's a fine-not-great prompt. Let's see how it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64f33f-328b-4609-b248-fa52214b5b76",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "For some tasks you can generate them yourselves. For our notebook, we have created a 10-datapoint dataset of some scraped ArXiv papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc80f9da-db1f-41c9-8db1-0f92b3acb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_ds = \"https://smith.langchain.com/public/42bbacae-e9b2-4410-a053-ce3c11abec83/d\"\n",
    "ds_name = \"Tweet Generator\"\n",
    "client.clone_public_dataset(public_ds)\n",
    "ds = client.read_dataset(dataset_name=ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a450e73-4556-4aa3-898e-e9e447b2cbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c51af-1a53-4530-885d-099f56bf27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = chain.invoke(example.inputs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dda2b0-e4f7-4394-9b65-6f4316399392",
   "metadata": {},
   "source": [
    "## 3. Predict\n",
    "\n",
    "We will refrain from defining metrics for now (it's quite subjective). Instead we will run the first version of the generator against the dataset and manually review + provide feedback on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54cd01c1-8859-4fe7-a8ed-1ef430c475a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def parse_tweet(response: str):\n",
    "    try:\n",
    "        return response.split(\"<tweet>\")[1].split(\"</tweet>\")[0].strip()\n",
    "    except:\n",
    "        return response.strip()\n",
    "\n",
    "\n",
    "def create_tweet_generator(prompt_str: str):\n",
    "    prompt = PromptTemplate.from_template(prompt_str)\n",
    "    return prompt | llm | StrOutputParser() | parse_tweet\n",
    "\n",
    "\n",
    "tweet_generator = create_tweet_generator(recommended_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87a9b2d-a2fe-4e55-bc50-6e7bef4f98ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'brief-reason-82' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/453ddc95-6353-4cb6-ba79-06b8a6f518b6/compare?selectedSessions=c66cc5bc-f9b3-4e31-a881-fc374da3a02c\n",
      "\n",
      "View all tests for Dataset Tweet Generator at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/453ddc95-6353-4cb6-ba79-06b8a6f518b6\n",
      "[------------------------------------------------->] 10/10"
     ]
    }
   ],
   "source": [
    "res = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9a554-7504-4070-9a2a-ed0c09e656fc",
   "metadata": {},
   "source": [
    "## 4. Label\n",
    "\n",
    "Now, we will use an annotation queue to score + add notes to the results. We will use this to iterate on our prompt!\n",
    "\n",
    "For this notebook, I will be logging two types of feedback:\n",
    "\n",
    "`note`- freeform comments on the runs\n",
    "\n",
    "`tweet_quality` - a 0-4 score of the generated tweet based on my subjective preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94a24156-a2a9-49ee-98e9-f2f3d8f9ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = client.create_annotation_queue(name=\"Tweet Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b6c2406-eb48-4abb-99f0-b8993ce607d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(project_name=res[\"project_name\"], execution_order=1)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae068c97-ced9-4496-b7a5-57213e493325",
   "metadata": {},
   "source": [
    "Now, go through the runs to label them. Return to this notebook when you are finished.\n",
    "\n",
    "![Queue](./img/queue.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ed075-38de-4a09-b073-63807039550e",
   "metadata": {},
   "source": [
    "## 4. Update\n",
    "\n",
    "With the human feedback in place, let's update the prompt and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75f8f65e-40af-4c40-8ca4-ca07831b28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def format_feedback(single_feedback, max_score=4):\n",
    "    if single_feedback.score is None:\n",
    "        score = \"\"\n",
    "    else:\n",
    "        score = f\"\\nScore:[{single_feedback.score}/{max_score}]\"\n",
    "    comment = f\"\\n{single_feedback.comment}\".strip()\n",
    "    return f\"\"\"<feedback key={single_feedback.key}>{score}{comment}\n",
    "</feedback>\"\"\"\n",
    "\n",
    "\n",
    "def format_run_with_feedback(run, feedback):\n",
    "    all_feedback = \"\\n\".join([format_feedback(f) for f in feedback])\n",
    "    return f\"\"\"<example>\n",
    "<tweet>\n",
    "{run.outputs[\"output\"]}\n",
    "</tweet>\n",
    "<annotations>\n",
    "{all_feedback}\n",
    "</annotations>\n",
    "</example>\"\"\"\n",
    "\n",
    "\n",
    "def get_formatted_feedback(project_name: str):\n",
    "    traces = list(client.list_runs(project_name=project_name, execution_order=1))\n",
    "    feedbacks = defaultdict(list)\n",
    "    for f in client.list_feedback(run_ids=[r.id for r in traces]):\n",
    "        feedbacks[f.run_id].append(f)\n",
    "    return [\n",
    "        format_run_with_feedback(r, feedbacks[r.id])\n",
    "        for r in traces\n",
    "        if r.id in feedbacks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fd4c807-ef3f-4520-a77f-ad813252f257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_feedback = get_formatted_feedback(res[\"project_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c907a-73d3-45c5-812f-9631bb63c21c",
   "metadata": {},
   "source": [
    "LLMs are especially good at 2 things:\n",
    "1. Generating grammatical text\n",
    "2. Summarization\n",
    "\n",
    "Now that we've left a mixture of scores and free-form comments, we can use an \"optimizer prompt\" ([wfh/optimizerprompt](https://smith.langchain.com/hub/wfh/optimizerprompt)) to incorporate the feedback into an updated prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b41aa18b-a99e-4927-a155-83b8cdb4c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://smith.langchain.com/hub/wfh/optimizerprompt\n",
    "optimizer_prompt = hub.pull(\"wfh/optimizerprompt\")\n",
    "\n",
    "\n",
    "def extract_new_prompt(gen: str):\n",
    "    return gen.split(\"<improved_prompt>\")[1].split(\"</improved_prompt>\")[0].strip()\n",
    "\n",
    "\n",
    "optimizer = optimizer_prompt | llm | StrOutputParser() | extract_new_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8f42771-a135-44c9-9534-e6f572089d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prompt = recommended_prompt\n",
    "new_prompt = optimizer.invoke(\n",
    "    {\n",
    "        \"current_prompt\": current_prompt,\n",
    "        \"annotated_predictions\": \"\\n\\n\".join(formatted_feedback).strip(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eac1918-1c85-420a-9519-a924a11a8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt\n",
      "\n",
      "\n",
      "Your task is to write an engaging tweet to market the following academic paper or open source project:\n",
      "\n",
      "<paper>\n",
      "{paper}\n",
      "</paper>\n",
      "\n",
      "Pay close attention to the abstract or project summary, as that will contain the key points you'll want to highlight in the tweet.  Think carefully about how to concisely summarize the work in a way that will be interesting and appealing to a broad audience on Twitter. \n",
      "\n",
      "The tweet should strike a balance between being clear and informative about the work, while also using some marketing language to generate excitement and interest. However, avoid being gimmicky or relying too heavily on buzzy jargon.  Focus on substance over style.\n",
      "\n",
      "Write out the full text of your proposed tweet inside <tweet> tags. The tweet must be under 280 characters in length.\n",
      "\n",
      "********************************************************************************\n",
      "New Prompt\n",
      "\n",
      "Your task is to write an engaging tweet to market the following academic paper or open source project:\n",
      "\n",
      "<paper>\n",
      "{paper}\n",
      "</paper>\n",
      "\n",
      "Here are the key elements to include in your tweet:\n",
      "\n",
      "1. Concisely summarize the most important new findings from the paper. Focus on the key advances rather than the minutiae of the methodology. \n",
      "\n",
      "2. Explain why the findings are important or how they could lead to new applications. Avoid overhyped terms like \"breakthrough\" and focus on clear, grounded explanations using concrete examples where possible.\n",
      "\n",
      "3. Briefly define any essential technical jargon that appears in your summary (e.g. what are \"spintronic devices\"?). Aim to make the significance of the work accessible to a broad audience.\n",
      "\n",
      "4. Credit the authors and/or their institutions, and include a link to the paper/project.\n",
      "\n",
      "Feel free to use more than 280 characters to achieve a good balance of being punchy and interesting while also including key context and explanations. But don't let it become too dense or long-winded.\n",
      "\n",
      "Here's an example of the kind of tone and content to aim for:\n",
      "\n",
      "<tweet>\n",
      "New record: 29.5% efficiency solar cells achieved by stacking perovskite-silicon tandem cell. That's 4% higher than standard Si cells! Promising path to ultra-high efficiency at lower costs. Perovskites are semiconductors that can be \"tuned\" to absorb different light colors.\n",
      "https://doi.org/10.1038/s41586-023-46736-2\n",
      "By M. Jeong et al. @SomaiyaVidyavihar \n",
      "</tweet>\n",
      "\n",
      "Don't copy this example directly, but use it as a guide for the style and level of detail to try to emulate for the paper provided.\n",
      "\n",
      "Write out the full text of your proposed tweet inside <tweet> tags.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Prompt\\n\\n\" + current_prompt)\n",
    "print(\"*\" * 80 + \"\\nNew Prompt\\n\\n\" + new_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316756d0-30d9-45bd-a3f4-e737bf4430de",
   "metadata": {},
   "source": [
    "## 5. Repeat!\n",
    "\n",
    "Now that we have an \"upgraded\" prompt, we can test it out again and repeat until we are satisfied with the result.\n",
    "\n",
    "If you find the prompt isn't converging to something you want, you can manually update the prompt (you are the optimizer in this case) and/or be more explicit in your free-form note feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2aef764-ef56-4e21-83ac-f51f7f0e7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'aching-vein-26' at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/453ddc95-6353-4cb6-ba79-06b8a6f518b6/compare?selectedSessions=8b937ad4-acea-4987-9c3d-db2c1edc25fc\n",
      "\n",
      "View all tests for Dataset Tweet Generator at:\n",
      "https://smith.langchain.com/o/30239cd8-922f-4722-808d-897e1e722845/datasets/453ddc95-6353-4cb6-ba79-06b8a6f518b6\n",
      "[------------------------------------------------->] 10/10"
     ]
    }
   ],
   "source": [
    "tweet_generator = create_tweet_generator(new_prompt)\n",
    "\n",
    "updated_results = client.run_on_dataset(\n",
    "    dataset_name=ds_name,\n",
    "    llm_or_chain_factory=tweet_generator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58ac7137-a6c1-4c5a-aacb-cc1bd66b0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.add_runs_to_annotation_queue(\n",
    "    q.id,\n",
    "    run_ids=[\n",
    "        r.id\n",
    "        for r in client.list_runs(\n",
    "            project_name=updated_results[\"project_name\"], execution_order=1\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ed160-28d4-493e-8e10-6420ded71e1a",
   "metadata": {},
   "source": [
    "Then review/provide feedback/repeat.\n",
    "\n",
    "Once you've provided feedback, you can continue here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f403a5f8-00b2-4d20-8d3b-b5f1cf050718",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_feedback = get_formatted_feedback(updated_results[\"project_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5103da25-8b28-44dc-b816-a972cff3c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap them out\n",
    "current_prompt = new_prompt\n",
    "new_prompt = optimizer.invoke(\n",
    "    {\n",
    "        \"current_prompt\": current_prompt,\n",
    "        \"annotated_predictions\": \"\\n\\n\".join(formatted_feedback).strip(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5e46e96-ad32-4251-8e51-72d9bf582a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Prompt\n",
      "\n",
      "Your task is to write an engaging tweet to market the following academic paper or open source project:\n",
      "\n",
      "<paper>\n",
      "{paper}\n",
      "</paper>\n",
      "\n",
      "Here are the key elements to include in your tweet:\n",
      "\n",
      "1. Concisely summarize the most important new findings from the paper. Focus on the key advances rather than the minutiae of the methodology. \n",
      "\n",
      "2. Explain why the findings are important or how they could lead to new applications. Avoid overhyped terms like \"breakthrough\" and focus on clear, grounded explanations using concrete examples where possible.\n",
      "\n",
      "3. Briefly define any essential technical jargon that appears in your summary (e.g. what are \"spintronic devices\"?). Aim to make the significance of the work accessible to a broad audience.\n",
      "\n",
      "4. Credit the authors and/or their institutions, and include a link to the paper/project.\n",
      "\n",
      "Feel free to use more than 280 characters to achieve a good balance of being punchy and interesting while also including key context and explanations. But don't let it become too dense or long-winded.\n",
      "\n",
      "Here's an example of the kind of tone and content to aim for:\n",
      "\n",
      "<tweet>\n",
      "New record: 29.5% efficiency solar cells achieved by stacking perovskite-silicon tandem cell. That's 4% higher than standard Si cells! Promising path to ultra-high efficiency at lower costs. Perovskites are semiconductors that can be \"tuned\" to absorb different light colors.\n",
      "https://doi.org/10.1038/s41586-023-46736-2\n",
      "By M. Jeong et al. @SomaiyaVidyavihar \n",
      "</tweet>\n",
      "\n",
      "Don't copy this example directly, but use it as a guide for the style and level of detail to try to emulate for the paper provided.\n",
      "\n",
      "Write out the full text of your proposed tweet inside <tweet> tags.\n",
      "********************************************************************************\n",
      "New Prompt\n",
      "\n",
      "Your task is to write an engaging tweet to market the following academic paper or open source project:\n",
      "\n",
      "<paper>\n",
      "{paper}\n",
      "</paper>\n",
      "\n",
      "Structure your tweet in the following way:\n",
      "\n",
      "1. Identify the key problem or opportunity that the new work addresses. This should be the attention-grabbing \"hook\" that leads your tweet.\n",
      "\n",
      "2. Concisely explain what the researchers did and how they did it. Focus on the most important and novel aspects of their work. Avoid getting bogged down in methodological details.\n",
      "\n",
      "3. Briefly explain any essential technical concepts to make the significance of the work more accessible to a broad audience. Use plain language rather than jargon where possible.\n",
      "\n",
      "4. Discuss the potential impact and applications of the work moving forward. Be specific and grounded rather than making hyperbolic claims. Explain how this work could lead to advances in the field.\n",
      "\n",
      "5. Provide a link to the paper or project, and credit the authors and their institutions. \n",
      "\n",
      "Aim for a total tweet length of 250-350 characters. Focus on being punchy and compelling while still including key details and context.\n",
      "\n",
      "Here's an example of a strong tweet following this structure:\n",
      "\n",
      "<tweet>\n",
      "Room-temp ferromagnetic semiconductor could revolutionize spintronics and quantum computing. Zhang & Sui grew graphene on nickel, opening a bandgap & splitting electron spins. Harnesses graphene's unique properties in new ways for nonvolatile memory & more.\n",
      "https://doi.org/10.1038/s41563-023-01587-y\n",
      "@BeijingNormalU @TsinghuaUni\n",
      "</tweet>\n",
      "\n",
      "Use this as a guide for the style and content to aim for. Write your tweet inside <tweet> tags.\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous Prompt\\n\\n\" + current_prompt)\n",
    "print(\"*\" * 80 + \"\\nNew Prompt\\n\\n\" + new_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b952f0d-a3e2-4e09-99eb-af75c03416f2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats! You've \"optimized\" a prompt on a subjective task using human feedback and an automatic prompt engineer flow. LangSmith makes it easy to score and improve LLM systems even when it is hard to craft a hard metric.\n",
    "\n",
    "You can push the optimized version of your prompt to the hub (here and in future iterations) to version each change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "817d82e4-98b4-4902-9f29-05df7a21621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/wfh/academic-tweet-generator/03670db0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub.push(\"wfh/academic-tweet-generator\", PromptTemplate.from_template(new_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22adabff-26ff-48ec-8faf-d0d43031f2c0",
   "metadata": {},
   "source": [
    "#### Extensions:\n",
    "\n",
    "We haven't optimized the meta-prompts above - feel free to make them your own by forking and updating them!\n",
    "Some easy extensions you could try out include:\n",
    "1. Including the full history of previous prompts and annotations (or most recent N prompts with feedback) in the \"optimizer prompt\" step. This may help it better converge (especially if you're using a small dataset)\n",
    "2. Updating the optimizer prompt to encourage usage of few-shot examples, or to encourage other prompting tricks.\n",
    "3. Incorporating an LLM judge by including the annotation few-shot examples and instructing it to critique the generated outputs: this could help speed-up the human annotation process.\n",
    "4. Generating and including a validation set (to avoid over-fitting this training dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
