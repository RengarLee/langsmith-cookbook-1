{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964403a2-efbb-4b81-8a9a-ac1e238cb0e0",
   "metadata": {},
   "source": [
    "# Evaluating a Traceable Function\n",
    "\n",
    "LangChain's `run_on_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b35e9cd-cbc0-496d-99c3-3be104f0e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def complete(*args, **kwargs):\n",
    "    return openai.ChatCompletion.create(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "@traceable()\n",
    "async def my_model(question: str, context: str):\n",
    "    import asyncio\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Respond to the user, taking into account the context: {context}\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question,\n",
    "        },\n",
    "    ]\n",
    "    await asyncio.sleep(0.1)\n",
    "    completion = complete(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    format = RunnableLambda(lambda x: x.choices[0].message.content)\n",
    "    return format.invoke(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67317932-2aff-4597-9742-b4ff4fbeff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith.evaluation.runner_utils import RunnableTraceable\n",
    "\n",
    "runnable_traceable = RunnableTraceable(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d0603d-33f5-4547-b6b0-be0ea58ae82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.run_helpers import get_run_tree_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb27f19a-f925-4068-aaee-218f059dae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "uid = uuid.uuid4()\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What's 2+2\",\n",
    "        \"context\": \"You are a pirate\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where did coffee originate from?\",\n",
    "        \"context\": \"You are a knight of King Arthur.\",\n",
    "    },\n",
    "]\n",
    "# dataset_name = f\"Evalutaing Traceables Walkthrough - {uid}\"\n",
    "# dataset = client.create_dataset(dataset_name)\n",
    "\n",
    "# client.create_examples(\n",
    "#     inputs=examples,\n",
    "#     dataset_id=dataset.id,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3caf1bbe-9c83-4077-8edd-7ea8184ce393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import trace_as_chain_group\n",
    "\n",
    "\n",
    "@traceable()\n",
    "async def group_traceable(examples):\n",
    "    with trace_as_chain_group(\"My Group\") as cb:\n",
    "        res = await runnable_traceable.abatch(examples, {\"callbacks\": cb})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304a1ab6-834d-462a-9edf-9e7c09e24186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ahoy matey! 2+2 be 4, me hearty!',\n",
       " 'Ah, fair traveler, the origins of coffee are said to lie in the lands of Ethiopia; a land filled with enchanting tales and rich history. According to legend, it was there that a goat herder named Kaldi first discovered the invigorating properties of the coffee plant. It is said that Kaldi noticed his goats became quite spirited after feasting on the red cherries of a certain shrub. Intrigued, he decided to try these cherries himself and discovered their stimulating effect. Word of this remarkable discovery spread, leading to the cultivation and eventual enjoyment of coffee throughout the kingdom and beyond.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await group_traceable(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97d5e91-f919-4c10-9200-76ca6e0aebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.smith import RunEvalConfig\n",
    "\n",
    "# evaluation = RunEvalConfig(\n",
    "#     evaluators=[\"criteria\"],\n",
    "# )\n",
    "\n",
    "# client.run_on_dataset(\n",
    "#     dataset_name=dataset_name,\n",
    "#     llm_or_chain_factory=my_model,\n",
    "#     evaluation=evaluation,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b09831-7b73-48cf-bd66-3758c8db2a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
