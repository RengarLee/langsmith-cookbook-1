{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Curate fine-tuning data with Lilac\n",
    "\n",
    "Lilac is an open-source product that helps you analyze, structure, and clean unstructured data with AI. You can use it to enrich datasets of LangChain runs to create better fine-tuning datasets.\n",
    "\n",
    "In this walkthrough, we will use Lilac on a dataset of LangSmith runs to check for PII and remove approximate duplicates.\n",
    "\n",
    "The basic workflow is as follows:\n",
    "\n",
    "- Create a LangSmith dataset of runs data.\n",
    "- Load LangSmith dataset into Lilac.\n",
    "- Filter and curate dataset using signals and concepts.\n",
    "- Export the dataset for fine-tuning.\n",
    "\n",
    "We will explain each of these steps in more detail below, but first, install some prerequisite packages.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In addition to Lilac and LangSmith, this walkthrough requires a couple of additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"lilac[pii]\" langdetect openai langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"<YOUR-API-KEY>\"\n",
    "unique_id = uuid.uuid4().hex[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Create LangSmith dataset\n",
    "\n",
    "We've included an example dataset in this repository that you can use to complete this walkthrough.\n",
    "\n",
    "This dataset was made by querying prompt and LLM runs from an example deployment of [chat langchain](https://github.com/langchain-ai/chat-langchain). \n",
    "\n",
    "For more information on how to query runs in LangSmith, check out the [docs](https://docs.smith.langchain.com/tracing/use-cases/export-runs/local) or explore some of the other recipes in this cookbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = f\"langsmith-prompt-runs-{unique_id}\"\n",
    "ds = client.create_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def create_example(line: str):\n",
    "    d = json.loads(line)\n",
    "    client.create_example(inputs=d['inputs'], outputs=d['outputs'], dataset_id=ds.id)\n",
    "\n",
    "with open('rag.jsonl', 'r', encoding='utf-8') as f:\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        executor.map(\n",
    "               create_example, \n",
    "            f\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the dataset. Lilac works best on flat dataset structures, so we will flatten (and stringify) some of the attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import into Lilac\n",
    "\n",
    "Next, we can import the LangSmith dataset into Lilac. Select the dataset name you created above, \n",
    "and run the code below. Once you've run the code, you can view the the results in Lilac's UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import lilac as ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from source langsmith...: 100%|█████████████████████████████████████| 369/369 [00:00<00:00, 87209.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"langsmith-prompt-runs-c8725493ede6\" written to ./langsmith-finetune/datasets/local/langsmith-prompt-runs-c8725493ede6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ll.set_project_dir('./langsmith-finetune')\n",
    "\n",
    "data_source = ll.sources.langsmith.LangSmithSource(\n",
    "    dataset_name=dataset_name,\n",
    ")\n",
    "\n",
    "config = ll.DatasetConfig(\n",
    "  namespace='local',\n",
    "  name=dataset_name+ uuid.uuid4().hex[:4],\n",
    "  source=data_source,\n",
    ")\n",
    "\n",
    "try:\n",
    "    dataset = ll.create_dataset(config)\n",
    "except:\n",
    "    dataset = ll.get_dataset(config)\n",
    "\n",
    "ll.start_server()\n",
    "# await ll.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Enrich Dataset\n",
    "\n",
    "You can explore and annotate the dataset in the app by navigating to the URL printed out by the local server above. I'd encourage you to try out their off-the-shelf \"concepts\" or try training your own.\n",
    "\n",
    "For the sake of this walkthrouugh, we will focus on using the Python API. You can follow along with the code below.\n",
    "\n",
    "#### Applying 'signals'\n",
    "\n",
    "Signals in Lilac refer to any function that is applied over a field. We will use a couple off-the-shelf \"signals\" to perform the following:\n",
    "\n",
    "- PII detection: we don't want to leak private data\n",
    "- Near duplicate detection: we want each training example to be informative\n",
    "\n",
    "These are useful for filtering bad examples from our dataset before fine-tuning a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing pii on local/langsmith-prompt-runs-c8725493ede6:('question',): 100%|█| 369/369 [00:00<00:00, 821.90it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"pii\" on local/langsmith-prompt-runs-c8725493ede6:('question',) took 0.451s.\n",
      "Wrote signal output to ./langsmith-finetune/datasets/local/langsmith-prompt-runs-c8725493ede6/question/pii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing pii on local/langsmith-prompt-runs-c8725493ede6:('output',): 100%|██| 369/369 [00:00<00:00, 387.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"pii\" on local/langsmith-prompt-runs-c8725493ede6:('output',) took 0.954s.\n",
      "Wrote signal output to ./langsmith-finetune/datasets/local/langsmith-prompt-runs-c8725493ede6/output/pii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing near_dup on local/langsmith-prompt-runs-c8725493ede6:('question',):   0%|      | 0/369 [00:00<?, ?it/s]\n",
      "Fingerprinting...: 369it [00:00, 15314.34it/s]\n",
      "\n",
      "Computing hash collisions...: 100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 892.79it/s]\u001b[A\n",
      "\n",
      "Clustering...: 100%|██████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 26533.31it/s]\u001b[A\n",
      "Computing near_dup on local/langsmith-prompt-runs-c8725493ede6:('question',): 100%|█| 369/369 [00:00<00:00, 5611.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"near_dup\" on local/langsmith-prompt-runs-c8725493ede6:('question',) took 0.067s.\n",
      "Wrote signal output to ./langsmith-finetune/datasets/local/langsmith-prompt-runs-c8725493ede6/question/near_dup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing near_dup on local/langsmith-prompt-runs-c8725493ede6:('output',):   0%|        | 0/369 [00:00<?, ?it/s]\n",
      "Fingerprinting...: 361it [00:00, 4263.73it/s]\n",
      "\n",
      "Computing hash collisions...: 100%|███████████████████████████████████████████████| 1/1 [00:00<00:00, 940.64it/s]\u001b[A\n",
      "\n",
      "Clustering...: 100%|██████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 40240.55it/s]\u001b[A\n",
      "Computing near_dup on local/langsmith-prompt-runs-c8725493ede6:('output',): 100%|█| 369/369 [00:00<00:00, 2926.11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing signal \"near_dup\" on local/langsmith-prompt-runs-c8725493ede6:('output',) took 0.127s.\n",
      "Wrote signal output to ./langsmith-finetune/datasets/local/langsmith-prompt-runs-c8725493ede6/output/near_dup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.compute_signal(ll.PIISignal(), 'question')\n",
    "dataset.compute_signal(ll.PIISignal(), 'output')\n",
    "\n",
    "# Apply min-hash LSH (https://en.wikipedia.org/wiki/MinHash) to detect approximate n-gram duplicates\n",
    "dataset.compute_signal(ll.NearDuplicateSignal(), 'question')\n",
    "dataset.compute_signal(ll.NearDuplicateSignal(), 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lilac has a lot more powerful capabilities like custom concepts and signals that you can apply. Check out their [docs](https://lilacml.com/blog/introducing-lilac.html) for more info, and see our [exploratory data analysis](../../exploratory-data-analysis/lilac/lilac.ipynb) noteboook for an introduction on using them with LangSmith datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to select path ('input',). Path part \"input\" not found in the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m ll\u001b[38;5;241m.\u001b[39mConceptSearch(\n\u001b[1;32m      2\u001b[0m     concept_namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     concept_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt-injection\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     embedding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msbert\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mdf()\n\u001b[1;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.local/prompt-injection/sbert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/lilac/data/dataset_duckdb.py:846\u001b[0m, in \u001b[0;36mDatasetDuckDB.select_rows\u001b[0;34m(self, columns, searches, filters, sort_by, sort_order, limit, offset, task_step_id, resolve_span, combine_columns, user)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m combine_columns:\n\u001b[1;32m    843\u001b[0m   schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_rows_schema(\n\u001b[1;32m    844\u001b[0m     columns, sort_by, sort_order, searches, combine_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdata_schema\n\u001b[0;32m--> 846\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanifest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_searches(searches, manifest)\n\u001b[1;32m    848\u001b[0m search_udfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_udfs(searches, manifest)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/lilac/data/dataset_duckdb.py:554\u001b[0m, in \u001b[0;36mDatasetDuckDB._validate_columns\u001b[0;34m(self, columns, source_schema, select_schema)\u001b[0m\n\u001b[1;32m    552\u001b[0m udf_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39msignal_udf]\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_udfs(udf_cols, source_schema)\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselect_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/lilac/data/dataset_duckdb.py:534\u001b[0m, in \u001b[0;36mDatasetDuckDB._validate_selection\u001b[0;34m(self, columns, select_schema)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_field\u001b[38;5;241m.\u001b[39mfields:\n\u001b[1;32m    533\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m path_part \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m current_field\u001b[38;5;241m.\u001b[39mfields:\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to select path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    535\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath part \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_part\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in the dataset.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    536\u001b[0m   current_field \u001b[38;5;241m=\u001b[39m current_field\u001b[38;5;241m.\u001b[39mfields[path_part]\n\u001b[1;32m    537\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to select path ('input',). Path part \"input\" not found in the dataset."
     ]
    }
   ],
   "source": [
    "query = ll.ConceptSearch(\n",
    "    concept_namespace='local',\n",
    "    concept_name='prompt-injection',\n",
    "    embedding='sbert',\n",
    "    path='input',\n",
    ")\n",
    "r = dataset.select_rows(['input'], searches=[query], limit=30)\n",
    "df = r.df()\n",
    "df['score'] = df['input.local/prompt-injection/sbert'].apply(lambda x: x[0]['score'])\n",
    "display(df.sort_values('score', ascending=False).head(10)[['input', 'score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice a number of these values being given high scores, even if they aren't prompt injection. \n",
    "You can further refine the concepts in the app or using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_examples = [\n",
    "    ll.concepts.ExampleIn(label=False, text=\"what is the final result of `import hashlib;\"),\n",
    "    ll.concepts.ExampleIn(label=False, text=\"생존자 는 몇 명인가요?\"),\n",
    "    ll.concepts.ExampleIn(label=False, text=\"생존자 중에 여성은 몇 명인가요\")\n",
    "]\n",
    "concept = db.edit('local', 'prompt-injection', ll.concepts.ConceptUpdate(insert=examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = dataset.select_rows(['input'], searches=[query], limit=30)\n",
    "df = r.df()\n",
    "df['score'] = df['input.local/prompt-injection/sbert'].apply(lambda x: x[0]['score'])\n",
    "display(df.sort_values('score', ascending=False).head(10)[['input', 'score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the enriched dataset\n",
    "\n",
    "Now let's prepare the dataset for fine-tuning, we will fetch the deduplicated rows and filter out any rows that may contain PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the current schema by running the following. Select the fields you want to export.\n",
    "# dataset.manifest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 369\n",
      "Filtered length: 312\n"
     ]
    }
   ],
   "source": [
    "df = dataset.to_pandas([\n",
    "    'question', \n",
    "    'chat_history',\n",
    "    'context',\n",
    "    'output', \n",
    "    'question.pii',\n",
    "    'question.near_dup',\n",
    "    'user_score'])\n",
    "\n",
    "print(f\"Original length: {len(df)}\")\n",
    "\n",
    "# Flatten the dataframe\n",
    "df['cluster_id'] = df['question.near_dup'].apply(lambda x: x['cluster_id'])\n",
    "df['contains_pii'] = df['question.pii'].apply(lambda x: bool([v for l in x.values() for v in l]))\n",
    "# Drop original dotted columns\n",
    "df.drop(columns=['question.near_dup', 'question.near_dup'], inplace=True)\n",
    "# Now filter for only rows for which contains_pii is false, user_score is 1.0\n",
    "df = df[(~df['contains_pii']) & (df['user_score'] != '0.0') & (~df['output'].isna())]\n",
    "# And drop the duplicate cluster IDs\n",
    "df = df.drop_duplicates(subset='cluster_id', keep='first')\n",
    "print(f\"Filtered length: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Finetune\n",
    "\n",
    "With the dataset filtered, we can now prepare it to a compatible format for fine-tuning.\n",
    "We will use OpenAI's fine-tuning endpoint for this, but you could also apply similar logic to finetune a Llama, T5, or other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messages(row):\n",
    "    # print(row)\n",
    "    chat_history = json.loads(row.chat_history) or []\n",
    "    roles = (\"assistant\", \"user\")\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Helpfully answer the questions about LangChain.\"}]\n",
    "    for i, msg in enumerate(chat_history):\n",
    "        messages.append(\n",
    "            {\"role\": roles[i%2], \"content\": str(msg[\"content\"])}\n",
    "            )\n",
    "    messages.append({\"role\": \"user\", \"content\": row.question})\n",
    "    messages.append({\"role\": \"assistant\", \"content\": row.output})\n",
    "    return messages\n",
    "\n",
    "messages = df.apply(create_messages, axis=1).tolist()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can fine-tune the model! This will take a while (20+ minutes), so we'd encourage you to further explore your local Lilac dataset\n",
    "while you wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File file-UrGGUOin9fManPfygLuDlELi ready after 96.76 seconds.\n",
      "Status=[running]... 1654.28s\r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "import openai\n",
    "\n",
    "# We will write the jsonl file in memory\n",
    "my_file = BytesIO()\n",
    "for m in messages:\n",
    "    my_file.write((json.dumps({\"messages\": m}) + \"\\n\").encode('utf-8'))\n",
    "\n",
    "my_file.seek(0)\n",
    "training_file = openai.File.create(\n",
    "  file=my_file,\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "\n",
    "# OpenAI audits each training file for compliance reasons.\n",
    "# This make take a few minutes\n",
    "status = openai.File.retrieve(training_file.id).status\n",
    "start_time = time.time()\n",
    "while status != \"processed\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    status = openai.File.retrieve(training_file.id).status\n",
    "print(f\"File {training_file.id} ready after {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "job = openai.FineTuningJob.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "status = openai.FineTuningJob.retrieve(job.id).status\n",
    "start_time = time.time()\n",
    "while status != \"succeeded\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    job = openai.FineTuningJob.retrieve(job.id)\n",
    "    status = job.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use fine-tuned model\n",
    "\n",
    "With the model fine-tuning complete, you can load the fine-tuned model directly in LangChain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"The LangChain Expression Language (LCEL) is a language used within LangChain to define expressions and transformations. It provides a set of functions and operators that can be used to perform various operations on data within a LangChain pipeline. \\\\n\\\\nLCEL allows you to manipulate and transform data by applying functions and operators to input values. It supports a wide range of operations, including string manipulation, mathematical calculations, conditional branching, and more. This flexibility makes it a powerful tool for building complex data processing pipelines.\\\\n\\\\nLCEL expressions can be used in various contexts within LangChain, such as when defining data sources, data sinks, or in intermediate steps of a data manipulation process. You can also use LCEL expressions to define custom functions and operators, allowing you to extend the capabilities of LangChain to suit your specific needs.\\\\n\\\\nOverall, LCEL provides a way to dynamically transform and manipulate data within LangChain, making it a key component in building sophisticated and flexible data processing workflows.\"', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=job.fine_tuned_model,\n",
    "    temperature=1,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Helpfully answer the questions about LangChain.\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model\n",
    "chain.invoke({\"input\": \"What's LangChain Expression Language?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "LangSmith makes it easy to collect unstructured data seen by your production LLM application. Lilac can make it easier to filter and analyze with sophisticated methods.\n",
    "\n",
    "In this tutorial you created a dataset of run traces, filtered by near-duplicates and looking for PII, then used the filtered dataset to fine-tune a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
